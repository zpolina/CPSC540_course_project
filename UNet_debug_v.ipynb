{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "DATA_DIR = \"./input\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import random\n",
    "import skimage.io\n",
    "from skimage import transform\n",
    "from skimage.viewer import ImageViewer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "def read_list_from_file(list_file, comment='#', func=None):\n",
    "    with open(list_file) as f:\n",
    "        lines  = f.readlines()\n",
    "\n",
    "    strings=[]\n",
    "    for line in lines:\n",
    "        s = line.split(comment, 1)[0].strip()\n",
    "        if s != '':\n",
    "            strings.append(s)\n",
    "    if func is not None:\n",
    "        strings=[func(s) for s in strings]\n",
    "\n",
    "    return strings\n",
    "        \n",
    "def run_make_one_mask():\n",
    "\n",
    "    split = 'names'\n",
    "    ids = read_list_from_file(DATA_DIR + '/names/' + split, comment='#')\n",
    "\n",
    "    num_ids = len(ids)\n",
    "    for i in range(num_ids):\n",
    "        id = ids[i]\n",
    "        image_files = glob.glob(DATA_DIR + '/' + id + '/images/*.png')\n",
    "\n",
    "        assert(len(image_files)==1)\n",
    "        image_file=image_files[0]\n",
    "        image = cv2.imread(image_file,cv2.IMREAD_COLOR)\n",
    "        H,W,C = image.shape\n",
    "        one_mask = np.zeros((H,W), dtype=bool)\n",
    "        mask_files =glob.glob(DATA_DIR + '/' + id + '/masks/*.png')\n",
    "        for mask_file in mask_files:\n",
    "            mask = cv2.imread(mask_file,cv2.IMREAD_GRAYSCALE)\n",
    "            one_mask = one_mask |(mask>128)\n",
    "\n",
    "        one_mask = (one_mask*255).astype(np.uint8)\n",
    "        cv2.imwrite(DATA_DIR + '/' + id + '/one_mask.png', one_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_make_one_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(image,label,angel=5,resize_rate=0.3, output_size=256):\n",
    "\n",
    "    flip = random.randint(0, 1)\n",
    "    size = image.shape[0]\n",
    "    sh = random.random()/2-0.25\n",
    "    rotate_angel = random.random()/180*np.pi*angel\n",
    "    sigma = random.uniform(0,0.6)\n",
    "    scaling = random.uniform(0.1,1)\n",
    "    \n",
    "    # Rescale\n",
    "    transform.rescale(image, scaling, mode='reflect')\n",
    "    transform.rescale(label, scaling, mode='reflect')   \n",
    "        \n",
    "    # Create affine transform\n",
    "    afine_tf = transform.AffineTransform(shear=sh,rotation=rotate_angel)\n",
    "    \n",
    "    # Apply transform to image data\n",
    "    image = transform.warp(image, inverse_map=afine_tf,mode='edge')\n",
    "    label = transform.warp(label, inverse_map=afine_tf,mode='edge')\n",
    "    \n",
    "    # Ramdomly flip frame\n",
    "    if flip:\n",
    "        image = image[:,::-1,:]\n",
    "        label = label[:,::-1]\n",
    "        \n",
    "    #Shuffle the RGB channels to get color invariance\n",
    "    p = [0,1,2]\n",
    "    random.shuffle(p)\n",
    "    image[:,:,:] = image[:,:,p]    \n",
    "    #Change exposure/intensity randomly:\n",
    "    imageAlp = image[:,:,2]  \n",
    "    imageRest = image[:,:,0:3]\n",
    "    if random.randint(0,1)==0:\n",
    "        #use clahe\n",
    "        image = exposure.equalize_adapthist(image)    \n",
    "    if random.randint(0,1)==0:\n",
    "        image = exposure.rescale_intensity(image,(0,random.uniform(0.5,1)))        \n",
    "    \n",
    "    #Rotate the image\n",
    "    rotate = random.randint(0,3)\n",
    "    image = transform.rotate(image, rotate*np.pi/2)\n",
    "    label = transform.rotate(label, rotate*np.pi/2)   \n",
    "    #Corrupt data a little\n",
    "    if sigma > 0:\n",
    "        image = np.minimum(np.maximum(0.0,image + np.random.normal(0, sigma, image.shape)/255.0),255.0)\n",
    "    \n",
    "    \n",
    "    # Randomly cropping image frame\n",
    "    rsize = random.randint(np.floor(resize_rate*size),size)\n",
    "    w_s = random.randint(0,size - rsize)\n",
    "    h_s = random.randint(0,size - rsize)\n",
    "    image = image[w_s:w_s+size,h_s:h_s+size,:]\n",
    "    label = label[w_s:w_s+size,h_s:h_s+size]\n",
    "    \n",
    "    \n",
    "    #Now we resize the image\n",
    "    image = transform.resize(image, (output_size, output_size))\n",
    "    label = transform.resize(label, (output_size, output_size))\n",
    "    image = image.transpose(2, 1, 0)\n",
    "    #label  = cv2.threshold(label, 128, 255, cv2.THRESH_BINARY)[1]\n",
    "    label[label > 0.] = 1\n",
    "    return image.astype(float), label.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class ScienceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, split, mode='train', transform= None):\n",
    "        super(ScienceDataset, self).__init__()\n",
    "        self.split = split\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        ids = read_list_from_file(DATA_DIR + '/names/' + split, comment='#')\n",
    "        self.ids = ids\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id   = self.ids[index]\n",
    "        name = id.split('/')[-1]\n",
    "        image_file = DATA_DIR + '/' + id + '/images/' + name +'.png'\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if self.mode in ['train']:\n",
    "            mask_file =  DATA_DIR + '/' + id + '/one_mask.png'\n",
    "            mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "            return self.transform(image,mask)\n",
    "\n",
    "        if self.mode in ['test']:\n",
    "            return self.transform(image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import *\n",
    "def image_show(name, image, resize=1):\n",
    "    H,W = image.shape[0:2]\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, image.astype(np.uint8))\n",
    "    cv2.resizeWindow(name, round(resize*W), round(resize*H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HIGHT =256\n",
    "def augment(image,mask):\n",
    "        image = cv2.resize(image,(WIDTH,HIGHT))\n",
    "        image = image.transpose(2, 1, 0)\n",
    "        mask  = cv2.resize(mask,(WIDTH,HIGHT))\n",
    "        mask  = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)[1]\n",
    "        mask[mask == 255.] = 1\n",
    "        return image.astype(float),mask.astype(float)\n",
    "\n",
    "dataset = ScienceDataset(\n",
    "        'names', mode='train', transform = data_aug\n",
    "    )\n",
    "sampler = RandomSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.01698027, 0.0195621 , 0.02042393, ..., 0.02421154,\n",
       "         0.02348771, 0.02170185],\n",
       "        [0.01768505, 0.01276637, 0.01436983, ..., 0.02592269,\n",
       "         0.02650966, 0.02126072],\n",
       "        [0.0183383 , 0.02267278, 0.02272115, ..., 0.02395205,\n",
       "         0.02474077, 0.0229647 ],\n",
       "        ...,\n",
       "        [0.02768914, 0.02957133, 0.03419073, ..., 0.04333054,\n",
       "         0.05179265, 0.05471086],\n",
       "        [0.02671863, 0.02858379, 0.0319523 , ..., 0.04411691,\n",
       "         0.05128024, 0.05338923],\n",
       "        [0.0241607 , 0.02785407, 0.03366561, ..., 0.04316877,\n",
       "         0.05227152, 0.05395211]],\n",
       "\n",
       "       [[0.01710708, 0.02015094, 0.01943791, ..., 0.02568571,\n",
       "         0.02489939, 0.02241055],\n",
       "        [0.01534537, 0.01025039, 0.01394382, ..., 0.0255337 ,\n",
       "         0.02581012, 0.02226071],\n",
       "        [0.01803845, 0.0207396 , 0.01956567, ..., 0.02520252,\n",
       "         0.0259987 , 0.02470937],\n",
       "        ...,\n",
       "        [0.02643818, 0.0279955 , 0.03377537, ..., 0.04461747,\n",
       "         0.05341933, 0.05370235],\n",
       "        [0.02607541, 0.02838505, 0.03225104, ..., 0.04412944,\n",
       "         0.05462858, 0.05347352],\n",
       "        [0.02572173, 0.03061835, 0.03419209, ..., 0.04055053,\n",
       "         0.04831224, 0.05202333]],\n",
       "\n",
       "       [[0.01958706, 0.02024409, 0.01861691, ..., 0.02403884,\n",
       "         0.02364462, 0.02190308],\n",
       "        [0.01984446, 0.01506068, 0.01485216, ..., 0.02422088,\n",
       "         0.02368977, 0.02298416],\n",
       "        [0.01620444, 0.01776684, 0.01831694, ..., 0.02480513,\n",
       "         0.02353008, 0.02285739],\n",
       "        ...,\n",
       "        [0.02518612, 0.02940464, 0.03450682, ..., 0.04328725,\n",
       "         0.05160562, 0.05281145],\n",
       "        [0.02639893, 0.03018865, 0.03535134, ..., 0.04075136,\n",
       "         0.04920865, 0.05121254],\n",
       "        [0.02762045, 0.02731305, 0.03266507, ..., 0.04022359,\n",
       "         0.05010609, 0.05325991]]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def UpDownConv(in_channels, mid_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "            *ConvRelu(in_channels, mid_channels, kernel_size=3, stride=1, padding=1 ),\n",
    "            *ConvRelu(mid_channels, out_channels, kernel_size=3, stride=1, padding=1 ),\n",
    "    )\n",
    "def ConvRelu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_shape, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        in_channels, height, width = in_shape\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            *ConvRelu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n",
    "            *ConvRelu(16, 32, kernel_size=3, stride=2, padding=1 ),\n",
    "        )\n",
    "        #64\n",
    "        self.down2 = UpDownConv(32, 64, 128)\n",
    "        #32\n",
    "        self.down3 = UpDownConv(128, 256, 512)\n",
    "        #16\n",
    "        self.down4 = UpDownConv(512, 512, 512)\n",
    "        #8\n",
    "        self.same = nn.Sequential(\n",
    "            *ConvRelu(512,512, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #16\n",
    "        self.up4 = UpDownConv(1024, 512, 512)\n",
    "        #16\n",
    "        self.up3 = UpDownConv(1024, 512, 128)\n",
    "        #32\n",
    "        self.up2 = UpDownConv(256, 128, 32)\n",
    "        #64\n",
    "        self.up1 = UpDownConv(64, 64, 32)\n",
    "        #128\n",
    "\n",
    "        self.up0 = nn.Sequential(\n",
    "            *ConvRelu(32, 32, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #256\n",
    "\n",
    "        self.classify = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        down1 = self.down1(x)\n",
    "        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n",
    "        down2 = self.down2(out)\n",
    "        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n",
    "        down3 = self.down3(out)\n",
    "        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n",
    "        down4 = self.down4(out)\n",
    "        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n",
    "        out   = self.same(out)\n",
    "        out   = F.upsample(out, scale_factor=2, mode='bilinear') #16\n",
    "        out   = torch.cat([down4, out],1)\n",
    "        out   = self.up4(out)\n",
    "        out   = F.upsample(out, scale_factor=2, mode='bilinear') #32\n",
    "        out   = torch.cat([down3, out],1)\n",
    "        out   = self.up3(out)\n",
    "        out   = F.upsample(out, scale_factor=2, mode='bilinear') #64\n",
    "        out   = torch.cat([down2, out],1)\n",
    "        out   = self.up2(out)\n",
    "        out   = F.upsample(out, scale_factor=2, mode='bilinear') #128\n",
    "        out   = torch.cat([down1, out],1)\n",
    "        out   = self.up1(out)\n",
    "        out   = F.upsample(out, scale_factor=2, mode='bilinear') #256\n",
    "        out   = self.up0(out)\n",
    "        out   = self.classify(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.8262e-02  4.5847e-02 -3.8566e-03  ...   6.3177e-02  1.1645e-01  5.3935e-02\n",
      " -5.4142e-02 -3.4450e-02 -1.9488e-02  ...   1.5964e-01  1.6915e-01  6.3270e-02\n",
      "  1.5994e-01  1.3885e-01  2.2499e-01  ...  -6.5189e-02  9.8443e-02  5.7684e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.2149e-01 -9.1006e-02 -8.2508e-02  ...  -2.3114e-01 -6.0849e-02  1.6745e-01\n",
      " -8.6020e-02 -2.3827e-01 -2.6479e-01  ...  -1.5360e-01  3.7407e-03  1.2322e-01\n",
      "  9.3998e-02 -1.3145e-01 -2.0767e-01  ...  -2.6521e-01 -2.1105e-01 -3.2904e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -5.3981e-03  1.5119e-01  2.4639e-01  ...  -3.0234e-02  2.3453e-02  4.7593e-04\n",
      "  4.7930e-02  6.8546e-03  1.5760e-01  ...   2.1348e-01  3.3936e-01  1.5158e-01\n",
      "  9.8182e-02 -2.5223e-02  3.3031e-03  ...   1.9469e-01  2.4480e-01  1.1176e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.6013e-02  7.8945e-02 -2.0442e-02  ...   2.4072e-01  3.5019e-01  4.2086e-01\n",
      "  7.1066e-02  1.7899e-01  6.1463e-02  ...   1.9753e-01  2.5520e-01  2.8257e-01\n",
      " -1.2509e-02  1.3108e-01  1.6720e-02  ...  -2.4836e-02 -1.3711e-02  6.6897e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  1.6277e-01  5.8369e-02  1.6515e-02  ...   1.7472e-01  2.0254e-01 -2.6821e-02\n",
      "  3.7324e-02 -9.8275e-02  2.3607e-02  ...   9.0532e-02 -4.7579e-02 -1.1119e-01\n",
      "  2.6123e-02 -2.7261e-02 -8.3197e-02  ...   2.0098e-01  3.3581e-02 -1.6878e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  5.0428e-04  2.0743e-01  1.6580e-01  ...   5.0686e-01  4.5258e-01  3.3091e-01\n",
      "  2.8876e-02  1.3351e-01  1.8463e-01  ...   4.8498e-01  4.5901e-01  3.4221e-01\n",
      " -2.6956e-02  2.7954e-02  3.2438e-02  ...   4.5383e-02  1.0265e-01  1.5654e-01\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "( 5 , 0 ,.,.) = \n",
      "  2.4864e-01  4.4733e-02 -1.5623e-02  ...  -1.1058e-01 -1.5274e-01 -9.7666e-02\n",
      "  1.8905e-01  2.9445e-02  9.8386e-02  ...   2.3681e-01  1.7765e-01 -1.9476e-02\n",
      "  8.9121e-02 -1.0118e-01  7.5127e-02  ...   1.7865e-01  2.5280e-01  3.9968e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.4648e-02 -8.7801e-03  8.7249e-02  ...   1.4956e-01  1.4016e-01  1.5065e-01\n",
      " -1.3631e-01 -1.6156e-01 -1.7240e-01  ...   5.6261e-02  1.8414e-01  1.5024e-01\n",
      "  3.1515e-02 -1.6075e-01 -2.5255e-01  ...   2.8590e-02  4.8524e-02  3.1415e-02\n",
      "      ⋮  \n",
      "\n",
      "( 6 , 0 ,.,.) = \n",
      "  1.8936e-01  4.5637e-02  1.2857e-02  ...   5.5681e-02  1.7828e-01  9.4635e-02\n",
      "  1.4953e-02 -1.0886e-01  1.9894e-02  ...   1.5187e-01  4.9571e-01  1.7014e-01\n",
      "  4.4051e-02 -1.4997e-01 -1.4260e-01  ...  -9.3254e-02  3.0585e-01  1.0407e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.6482e-02 -6.5398e-02 -4.3683e-02  ...   2.0403e-01  1.6872e-01  9.6987e-02\n",
      " -1.3334e-02  5.4177e-02  8.8974e-02  ...  -3.7590e-03 -6.8879e-02  1.0172e-01\n",
      " -5.0188e-02 -5.7580e-02 -3.3949e-02  ...  -2.7820e-02 -2.2503e-01 -1.4895e-01\n",
      "      ⋮  \n",
      "\n",
      "( 7 , 0 ,.,.) = \n",
      "  1.1853e-03  2.1192e-01  1.8790e-01  ...   6.4129e-02  3.8419e-02 -7.3660e-02\n",
      " -1.0431e-01  1.0302e-01 -4.6822e-02  ...   4.3826e-01  4.4884e-01  1.5035e-01\n",
      " -5.4616e-02  4.0396e-03 -2.0655e-01  ...   4.8328e-01  4.1443e-01  1.5035e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6313e-01  1.4416e-01  2.0144e-02  ...   2.8487e-02  1.7636e-01  2.3657e-01\n",
      "  3.5484e-02  1.5067e-02 -5.1003e-02  ...  -2.4546e-01 -4.7158e-02  5.5840e-02\n",
      " -1.2366e-02 -1.2048e-01 -1.6100e-01  ...  -2.8023e-01 -2.6978e-01 -1.7938e-01\n",
      "[torch.FloatTensor of size 8x1x256x256]\n",
      "\n",
      "<class '__main__.UNet'>\n",
      "UNet(\n",
      "  (down1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (down2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (down3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (down4): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (same): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (up4): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (up3): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (up2): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (up1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (up0): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (classify): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = 1\n",
    "batch_size  = 8\n",
    "C = 3\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "inputs = torch.randn(batch_size,C,HIGHT,WIDTH)\n",
    "labels = torch.LongTensor(batch_size,HIGHT,WIDTH).random_(1).type(torch.FloatTensor)\n",
    "\n",
    "net = UNet(in_shape=(C,HIGHT,WIDTH), num_classes=1).train()\n",
    "x = Variable(inputs)\n",
    "y = Variable(labels)\n",
    "logits = net.forward(x)\n",
    "\n",
    "probs = F.sigmoid(logits)\n",
    "probs_flat = probs.view (-1)\n",
    "targets_flat = y.view(-1)\n",
    "\n",
    "print('logits')\n",
    "print(logits)\n",
    "loss = nn.BCELoss()\n",
    "output = loss(probs_flat, targets_flat)\n",
    "output.backward()\n",
    "\n",
    "print(type(net))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7288\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "LR = 0.0002\n",
    "batch_size = 5\n",
    "net = UNet(in_shape=(C,HIGHT,WIDTH), num_classes=1).train()\n",
    "epochs = 1\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "def train():\n",
    "    optimizer = \\\n",
    "                optim.Adam(net.parameters(),\n",
    "                           lr= LR, betas=(0.5, 0.999))\n",
    "    train_dataset = ScienceDataset(\n",
    "                                'names', mode='train',\n",
    "                                transform = data_aug)\n",
    "    train_loader  = DataLoader(\n",
    "                        train_dataset,\n",
    "                        sampler = RandomSampler(train_dataset),\n",
    "                        batch_size  = batch_size,\n",
    "                        drop_last   = True,\n",
    "                        num_workers = 8)\n",
    "    i = 0\n",
    "    while  i < epochs:  \n",
    "        sum_train_loss = 0.0\n",
    "        sum_train_acc  = 0.0\n",
    "        sum = 0\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        for index, data  in enumerate(train_loader):\n",
    "            image,mask = data\n",
    "            print(image.shape)\n",
    "            tensors = Variable(image)\n",
    "            masks   = Variable(mask)\n",
    "            logits  = net(tensors.float())\n",
    "            probs   = F.sigmoid(logits).view(-1)\n",
    "            masks_flat = masks.view(-1)\n",
    "            print(probs.shape)\n",
    "            print(masks_flat)\n",
    "            loss = nn.BCELoss()\n",
    "            output = loss(probs, masks_flat.float())\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            adjust_learning_rate(optimizer, i)\n",
    "            batch_loss = output.data[0]\n",
    "            sum_train_loss += batch_loss\n",
    "            print('\\r %0.2f| %0.4f| %0.4f  %0.4f  ',i, LR, batch_loss, sum_train_loss)\n",
    "\n",
    "        i = i +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6809605956077576 0.6809605956077576\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6722209453582764 1.353181540966034\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6502050161361694 2.0033865571022034\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6880558133125305 2.691442370414734\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6748801469802856 3.3663225173950195\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6769677400588989 4.0432902574539185\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6539501547813416 4.69724041223526\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.677045464515686 5.374285876750946\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6575204133987427 6.031806290149689\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.65693199634552 6.688738286495209\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6689761281013489 7.357714414596558\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6553251147270203 8.013039529323578\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6712571382522583 8.684296667575836\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6461460590362549 9.330442726612091\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6370720267295837 9.967514753341675\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6425787806510925 10.610093533992767\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6336326599121094 11.243726193904877\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6322156190872192 11.875941812992096\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6369026303291321 12.512844443321228\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6283985376358032 13.141242980957031\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6567038893699646 13.797946870326996\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6676995158195496 14.465646386146545\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6310471296310425 15.096693515777588\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6315130591392517 15.72820657491684\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6230531334877014 16.35125970840454\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6248152852058411 16.976074993610382\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6208322048187256 17.596907198429108\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6022024750709534 18.19910967350006\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6251860857009888 18.82429575920105\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6349347829818726 19.459230542182922\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6120336651802063 20.07126420736313\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6173175573348999 20.68858176469803\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6332007646560669 21.321782529354095\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6155706644058228 21.937353193759918\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5979866981506348 22.535339891910553\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5995217561721802 23.134861648082733\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5941454172134399 23.729007065296173\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5846037268638611 24.313610792160034\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.643974244594574 24.957585036754608\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6079148054122925 25.5654998421669\n",
      "torch.Size([5, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6085004806518555 26.174000322818756\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6376951932907104 26.811695516109467\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6177183985710144 27.42941391468048\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.599848747253418 28.0292626619339\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6289160251617432 28.658178687095642\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5938382744789124 29.252016961574554\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6057143807411194 29.857731342315674\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6003533601760864 30.45808470249176\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5928909182548523 31.050975620746613\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6306739449501038 31.681649565696716\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6172992587089539 32.29894882440567\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6723300218582153 32.971278846263885\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6017542481422424 33.57303309440613\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6270655989646912 34.20009869337082\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5994304418563843 34.7995291352272\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5942703485488892 35.39379948377609\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5960360765457153 35.98983556032181\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 1\n",
      " 1\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5792344212532043 36.56906998157501\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5585610866546631 37.127631068229675\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5684703588485718 37.69610142707825\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.619453489780426 38.31555491685867\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6256062984466553 38.94116121530533\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5848761200904846 39.52603733539581\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.555317759513855 40.08135509490967\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6090867519378662 40.690441846847534\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.586108922958374 41.27655076980591\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5959262847900391 41.87247705459595\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5699576139450073 42.442434668540955\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5525879263877869 42.99502259492874\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5759331583976746 43.570955753326416\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5843278765678406 44.15528362989426\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5605661273002625 44.71584975719452\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.6426242589950562 45.358474016189575\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5872753858566284 45.945749402046204\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5436731576919556 46.48942255973816\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5700501203536987 47.05947268009186\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5494500398635864 47.608922719955444\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5562057495117188 48.16512846946716\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5760351419448853 48.74116361141205\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5764795541763306 49.31764316558838\n",
      "torch.Size([5, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.591711163520813 49.90935432910919\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5830492973327637 50.492403626441956\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5569607019424438 51.0493643283844\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5755199193954468 51.624884247779846\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5476678013801575 52.172552049160004\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5869609117507935 52.7595129609108\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n",
      " %0.2f| %0.4f| %0.4f  %0.4f   0 0.0002 0.5943533182144165 53.353866279125214\n",
      "torch.Size([5, 3, 256, 256])\n",
      "torch.Size([327680])\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.DoubleTensor of size 327680]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-33:\n",
      "Process Process-37:\n",
      "Process Process-40:\n",
      "Process Process-34:\n",
      "Process Process-35:\n",
      "Process Process-36:\n",
      "Process Process-38:\n",
      "Process Process-39:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/polinazablotskaia/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-205-9101fd0be371>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.save(net.state_dict(), DATA_DIR +'/checkpoint/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
